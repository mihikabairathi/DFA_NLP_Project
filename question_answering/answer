#!/usr/bin/env python3
import argparse
import nltk
import spacy
from spacy import displacy
from collections import Counter
import en_core_web_sm
import string
import os
os.environ["NLTK_DATA"] = "nltk_data"
from nltk.corpus import wordnet
#import corefRes
import phrase_label_spacy
import tf_idf
import sys
from spacy.pipeline import Sentencizer
from spacy.lang.en import English
import GenerateSomeQuestions as cqg
from pattern.en import conjugate
from pattern.en import PAST, PRESENT

class Sentence():
    def __init__(self, original, lemmatized):
        self.original = original
        self.lemmatized = lemmatized


class Parser():
    def __init__(self):
        self.weights = {
            "CC": 0.05, #not important
            "CD": 0.1, 
            "DT": 0.05, #not important
            "EX": 0.1,
            "FW": 0.1,
            "IN": 0.05, #not important
            "JJ": 0.3,
            "JJR": 0.3,
            "JJS": 0.3,
            "LS": 0.05, #not important
            "MD": 0.1,
            "NN": 0.6,
            "NNS": 0.6,
            "NNP": 0.75,
            "NNPS": 0.75,
            "PDT": 0.1,
            "POS": 0.15,
            "PRP": 0.2,
            "PRP$": 0.2,
            "RB": 0.3,
            "RBR": 0.3,
            "RBS": 0.3,
            "RP": 0.1,
            "TO": 0.05, #not important
            "UH": 0.05, #not important
            "VB": 0.6,
            "VBD": 0.4,
            "VBG": 0.4,
            "VBN": 0.4,
            "VBP": 0.4,
            "VBZ": 0.4,
            "WDT": 0.4,
            "WP": 0.4,
            "WP$": 0.4,
            "WRB": 0.4,
            ".": 0.05,
            "''": 0.05
        }

        self.ques_weights = {
            "CC": 0.05, #not important
            "CD": 0.1, 
            "DT": 0.05, #not important
            "EX": 0.1,
            "FW": 0.1,
            "IN": 0.05, #not important
            "JJ": 0.3,
            "JJR": 0.3,
            "JJS": 0.3,
            "LS": 0.05, #not important
            "MD": 0.1,
            "NN": 0.6,
            "NNS": 0.6,
            "NNP": 0.75,
            "NNPS": 0.75,
            "PDT": 0.1,
            "POS": 0.15,
            "PRP": 0.2,
            "PRP$": 0.2,
            "RB": 0.3,
            "RBR": 0.3,
            "RBS": 0.3,
            "RP": 0.1,
            "TO": 0.05, #not important
            "UH": 0.05, #not important
            "VB": 0.6,
            "VBD": 0.5,
            "VBG": 0.5,
            "VBN": 0.5,
            "VBP": 0.5,
            "VBZ": 0.5,
            "WDT": 0.4,
            "WP": 0.4,
            "WP$": 0.4,
            "WRB": 0.4,
            ".": 0.05,
            "''": 0.05,
            ",": 0.05
        }
        self.nlp = en_core_web_sm.load()

    def question_parser(self, question):
        tokens = nltk.word_tokenize(question)
        tagged = nltk.pos_tag(tokens)
        topTen = len(tokens)//1.5
        mappedVals = []
        # Extracts more important words from text based on manual weight
        # dictionary
        for tag in tagged:
            mappedVals.append((tag[0], self.ques_weights[tag[1]]))
        mostImp = []
        while len(mostImp) < topTen:
            bestWord = None
            bestScore = 0
            for word in mappedVals:
                if word[1] > bestScore:
                    bestWord = word
                    bestScore = word[1]
            mostImp.append(bestWord)
            mappedVals.remove(bestWord)
        topWords = []
        for word in mostImp:
            topWords.append(word[0])
        
        # Using SpaCy for named entity recognition
        ner = self.nlp(question)

        #print([(X.text, X.label_) for X in ner.ents])
        #print(tagged)
        #print(topWords)
        return topWords
    
    def preprocess_text(self, text):
        # Replaces text with lemmatized form when found
        sentences = []
        start = 0
        nlp = English()
        sentencizer = nlp.create_pipe("sentencizer")
        nlp.add_pipe(sentencizer)
        doc = nlp(text)    
        sentences_lemm = []
        for sentence in doc.sents:
            sentence = str(sentence)
            sentences_lemm.append(Sentence(sentence, self.lemmatize(sentence)))
        return sentences_lemm

    def lemmatize(self, sentence):
        # Lemmatizes the words in a sentence
        lemmas = [(x.orth_,x.pos_, x.lemma_) for x in [y 
                                      for y
                                      in self.nlp(sentence) 
                                      if not y.is_stop and y.pos_ != 'PUNCT']]
        lemma_sent = []
        lemma_i = 0
        for word in sentence.split():
            if len(word) == 0: continue
            if word[-1] in string.punctuation:
                word = word[:-1]
            if len(word) == 0: continue
            if word[0] in string.punctuation:
                word = word[1:]
            if len(word) == 0: continue
            if lemmas != [] and (lemma_i >= len(lemmas) or word != lemmas[lemma_i][0]):
                lemma_sent.append(word)
            elif len(lemmas) != 0:
                lemma_sent.append(lemmas[lemma_i][2])
                lemma_i += 1
        return " ".join(lemma_sent)

    def extract_sentences_keyword(self, text, question):
        # Extracts sentences that most likely contain the answer
        question = self.lemmatize(question)
        keywords = self.question_parser(question)
        process_text = self.preprocess_text(text)
        result = []
        result2 = []
        result3 = []
        best = None
        bestRatio = 0
        for sentence in process_text:
            if not sentence.original[0].isalpha():
                continue
            if len(sentence.original.split(" ")) < 3:
                continue
            count = 0
            seen = set()
            for word in sentence.lemmatized.split():
                if word in keywords:
                    count += 1
                    if word not in seen:
                        seen.add(word)
                else:
                    # similarity checking
                    for kword in keywords:
                        try:
                            w1s = wordnet.synsets(word)
                            w2s = wordnet.synsets(kword)
                            found = False
                            for w1 in w1s:
                                if not found:
                                    for w2 in w2s:
                                        if w1.wup_similarity(w2) > 0.9:
                                            count += 1
                                            seen.add(word)
                                            found = True
                                            break
                                else:
                                    break
                        except:
                            continue
            bigram_count = self.count_bigram(sentence, question)
            trigram_count = self.count_trigram(sentence, question)
            unique_count = len(seen)
            final_count = count*.3 + bigram_count*.2 + unique_count*.4 + trigram_count*.2
            if final_count >= (len(keywords)*.6+len(question.split(" "))*2*.4)*0.2:
                result.append(sentence.original)
                ratio = count/(len(sentence.original.split(" ")))
                if ratio > bestRatio:
                    bestRatio = ratio
                    best = sentence.original
            # To account for shorter sentences
            elif len(question.split(" ")) < 5:
                if unique_count >=2:
                    result.append(sentence.original)
                    ratio = count/(len(sentence.original.split(" ")))
                    if ratio > bestRatio:
                        bestRatio = ratio
                        best = sentence.original
                elif unique_count >=2:
                    result2.append(sentence.original)
                elif unique_count >=1:
                    result3.append(sentence.original)
        # Comment out these two lines to revert to previous "best" measure
        result = list(set(result))
        best = tf_idf.compareToOriginal(question, result)
        return result, best, len(result)

    def count_bigram(self, sentence, question):
        # counts the number of bigram occurences from the question in the sentence
        count = 0
        question = "START " + question
        q_words = question.split(" ")
        s_words = sentence.lemmatized.split(" ")
        for i in range(1, len(q_words)):
            # Possibily add in similarity checking here too
            for j in range(len(s_words)):
                if j == 0:
                    count += question.count("START " + s_words[0])
                else:
                    count += question.count(s_words[j-1] + " " + s_words[j])
        return count

    def count_trigram(self, sentence, question):
        # counts the number of trigram occurences from the question in a sentence
        count = 0
        question = "START START " + question
        q_words = question.split(" ")
        s_words = sentence.lemmatized.split(" ")
        for i in range(2, len(q_words)):
            for j in range(len(s_words)):
                # Possibily add in similarity checking here too
                if j == 0:
                    prev1 = "START"
                    prev2 = "START"
                elif j == 1:
                    prev1 == "START"
                    prev2 = s_words[j-1]
                else:
                    prev1 = s_words[j-2]
                    prev2 = s_words[j-1]
                count += question.count(prev1 + " " + prev2 + " " + s_words[j])
        return count

    def get_possible_answers(self, text, question):
        # Get all the sentences that possibly contain the answer
        keywords = self.question_parser(self.lemmatize(question))
        return self.extract_sentences_keyword(text, question)
    
    def formatWhereAnswer(self, q_words, ans, nlp):
        # formats the grammar of the where question answers
        if q_words[-1] == "?": q_words = q_words[:-1]
        elif q_words[-1][-1] == "?": q_words[-1] = q_words[-1].replace("?", "")
        question = " ".join(q_words)
        doc = nlp(question)
        if doc[1].pos_ == "AUX" or doc[1].pos_ == "VERB":
            ind = 0
            for i in range(1, len(q_words)):
                if doc[i].pos_ == "VERB":
                    ind = i
                    break
            if q_words[1] == "did":
                ans = ans.replace("did ", "", 1)
                try:
                    conj = conjugate(q_words[ind], tense = PAST)
                except:
                    conj = conjugate(q_words[ind], tense = PAST)
                ans = ans.replace(q_words[ind], conj)
            elif q_words[1] == "does":
                ans = ans.replace("does ", "", 1)
                try:
                    conj = conjugate(q_words[ind], tense = PRESENT, person = 3)
                except:
                    conj = conjugate(q_words[ind], tense = PRESENT, person = 3)
                ans = ans.replace(q_words[ind], conj)
            elif q_words[1] == "do":
                ans = ans.replace(f'{q_words[1]} ', "", 1)
            else:
                ans_words = ans.split(" ")
                chunks = phrase_label_spacy.getNounChunks(ans)
                longest = ""
                for chunk in chunks:
                    if ans.find(chunk) == len(ans_words[0]) + 1 and len(chunk) > len(longest):
                        longest = chunk
                if longest != "":
                    ans = ans.replace(f'{ans_words[0]} {longest}', f'{longest} {ans_words[0]}', 1)
                ans_ann = nlp(ans)
                for i in range(len(ans_ann)):
                    if ans_ann[i].pos_ == "VERB" and ans_ann[i+1].pos_ == "AUX":
                        ans = ans.replace(f'{ans_ann[i].text} {ans_ann[i+1].text}', f'{ans_ann[i+1].text} {ans_ann[i].text}', 1)
                        break
        return ans

    def getWhereAnswer(self, question, bestAnswer):
        # Gets answer of the where questions
        words = question.split(" ")
        main,qverb = (" ".join(words[2:]), words[1])
        main.replace("?", "")
        preposition = "in"
        nlp = en_core_web_sm.load()
        if main[-1] == "?":
            main = main[:-1]
        phrases = phrase_label_spacy.getNounVerbPhrasePairs(bestAnswer)
        if len(phrases) == 0:
            nouns = phrase_label_spacy.getNounPhrases(bestAnswer)
            prep = nlp(main.split(" ")[-1])
            if prep[0].pos_ == "ADP":
                main = " ".join(main.split(" ")[:-1])
                preposition = prep[0].text
            ans =  f'{main} {qverb} {preposition} {nouns[0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        if len(phrases) == 1:
            prep = nlp(main.split(" ")[-1])
            if prep[0].pos_ == "ADP":
                main = " ".join(main.split(" ")[:-1])
                preposition = prep[0].text
            ans =  f'{main} {qverb} {preposition} {phrases[0][0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        possible = []
        for phrase in phrases:
            flag = True
            noun, verb = phrase
            for w in noun.split(" "):
                if w in question and not nlp.vocab[w].is_stop:
                    flag = False
            if flag:
                possible.append(phrase)
        if len(possible) == 1:
            prep = nlp(main.split(" ")[-1])
            if prep[0].pos_ == "ADP":
                main = " ".join(main.split(" ")[:-1])
                preposition = prep[0].text
            ans =  f'{main} {qverb} {preposition} {possible[0][0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        elif len(possible) == 0:
            possible = phrases
        np = self.bestNounPhrase(possible, question)
        prep = nlp(main.split(" ")[-1])
        if prep[0].pos_ == "ADP":
            main = " ".join(main.split(" ")[:-1])
            preposition = prep[0].text
        ans =  f'{main} {qverb} {preposition} {np}.'
        return self.formatWhereAnswer(words, ans, nlp)
    
    def bestNounPhrase(self, possible, question):
        # Gets the noun phrases with the most keywords in their corresponding
        # verb phrase
        bestNoun = None
        bestVerb = None
        bestScore = 0
        for noun, verb in possible:
            count = 0
            question_lem = self.lemmatize(question)
            verb_lem = self.lemmatize(verb)
            keywords = self.question_parser(question_lem)
            for word in verb_lem.split(" "):
                if word in keywords:
                    count += 1
            ratio = count/len(verb_lem.split(" "))
            if ratio > bestScore:
                bestScore = ratio
                bestNoun, bestVerb = noun, verb
        return bestNoun

    def getWhoAnswer(self, question, bestAnswer):
        #gets the answer for a who questions
        phrases = phrase_label_spacy.getNounVerbPhrasePairs(bestAnswer)
        words = question.split(" ")
        nlp = en_core_web_sm.load()
        if len(phrases) == 1:
            ans = question.replace(words[0], phrases[0][0], 1)
            return self.formatWhatAnswer(ans, nlp)
        possible = []
        for phrase in phrases:
            flag = True
            noun, verb = phrase
            for w in noun.split(" "):
                if w in question and not nlp.vocab[w].is_stop:
                    flag = False
            if flag:
                possible.append(phrase)
        if len(possible) == 1:
            ans = question.replace(words[0], possible[0][0], 1)
            return self.formatWhatAnswer(ans, nlp)
        elif len(possible) == 0:
            possible = phrases
        np = self.bestNounPhrase(possible, question)
        ans = question.replace(words[0], np, 1)
        return self.formatWhatAnswer(ans, nlp)

    def formatWhatAnswer(self, ans, nlp):
        last = ans.split(" ")[-1]
        last_w = nlp(last)
        for aux in {" did ", " had "}:
            ans = ans.replace(aux, " was the one that ", 1)
            if last_w.pos_ == "VERB":
                try:
                    conj = conjugate(last_w.text, tense = PAST)
                except:
                    conj = conjugate(last_w.text, tense = PAST)
                ans = ans.replace(last, conj)
        for aux in {" do ", " have "}:
            ans = ans.replace(aux, " are the ones that ", 1)
            if last_w.pos_ == "VERB":
                try:
                    conj = conjugate(last_w.text, tense = PRESENT)
                except:
                    conj = conjugate(last_w.text, tense = PRESENT)
                ans = ans.replace(last, conj)
        for aux in {" does ", " has "}:
            ans = ans.replace(aux, " is the one that ", 1)
            if last_w.pos_ == "VERB":
                try:
                    conj = conjugate(last_w.text, tense = PRESENT, person = 3)
                except:
                    conj = conjugate(last_w.text, tense = PRESENT, person = 3)
                ans = ans.replace(last, conj)
        ans = ans.replace("will", "will be that one that", 1)
        return ans

    def getWhatAnswer(self, question, bestAnswer):
        #gets the answer for a who questions
        phrases = phrase_label_spacy.getNounVerbPhrasePairs(bestAnswer)
        beginning = phrase_label_spacy.splitWhatQuestion(question)
        words = question.split(" ")
        nlp = en_core_web_sm.load()
        if len(phrases) == 1:
            ans =  question.replace(beginning, phrases[0][0], 1)
            return self.formatWhatAnswer(ans, nlp)
        possible = []
        for phrase in phrases:
            flag = True
            noun, verb = phrase
            for w in noun.split(" "):
                if w in question and not nlp.vocab[w].is_stop:
                    flag = False
            if flag:
                possible.append(phrase)
        if len(possible) == 1:
            ans = question.replace(beginning, possible[0][0], 1)
            return self.formatWhatAnswer(ans, nlp)
        elif len(possible) == 0:
            possible = phrases
        np = self.bestNounPhrase(possible, question)
        ans = question.replace(beginning, np, 1)
        return self.formatWhatAnswer(ans, nlp)

    def yesNoAnswer(self, question, bestAnswer):
        # Really basic negation checking right now
        q = "not" in question
        a = "not" in bestAnswer
        if (q and a) or (not q and not a):
            return "Yes."
        else:
            return "No."

    def getWhyAnswer(self, question, bestAnswer):
        # gets the answer for a why question
        words = bestAnswer.split(" ")
        if "because" in bestAnswer:
            i = words.index("because")
            reason =  " ".join(words[i+1:])
            split = "because"
        elif "since" in bestAnswer:
            i = words.index("since")
            reason =  " ".join(words[i+1:])
            split = "since"
        elif "due to" in bestAnswer:
            i = words.index("due")
            reason = " ".join(words[i+2:])
            split = "due to"
        elif "as" in bestAnswer:
            i = words.index("as")
            reason = " ".join(words[i+1:])
            split = "as"
        else:
            return bestAnswer
        q_words = question.split(" ")
        if q_words[-1] == "?": q_words = q_words[:-1]
        elif q_words[-1][-1] == "?": q_words[-1] = q_words[-1].replace("?", "")
        nlp = en_core_web_sm.load()
        doc = nlp(question)
        ans = f'{" ".join(q_words[1:])} {split} {reason}'
        aux = nlp(q_words[1])
        if aux[0].pos_ == "AUX" or aux[0].pos_ == "VERB":
            ind = 0
            for i in range(1, len(q_words)):
                if doc[i].pos_ == "VERB":
                    ind = i
                    break
            if q_words[1] == "did":
                ans = ans.replace("did ", "", 1)
                try:
                    conj = conjugate(q_words[ind], tense = PAST)
                except:
                    conj = conjugate(q_words[ind], tense = PAST)
                ans = ans.replace(q_words[ind], conj)
            elif q_words[1] == "does":
                ans = ans.replace("does ", "", 1)
                try:
                    conj = conjugate(q_words[ind], tense = PRESENT, person = 3)
                except:
                    conj = conjugate(q_words[ind], tense = PRESENT, person = 3)
                ans = ans.replace(q_words[ind], conj)
            elif q_words[1] == "do":
                ans = ans.replace(f'{q_words[1]} ', "", 1)
            else:
                ans_words = ans.split(" ")
                chunks = phrase_label_spacy.getNounChunks(ans)
                longest = ""
                for chunk in chunks:
                    if ans.find(chunk) == len(ans_words[0]) + 1 and len(chunk) > len(longest):
                        longest = chunk
                ans = ans.replace(f'{ans_words[0]} {longest}', f'{longest} {ans_words[0]}', 1)
        return ans

    def getDatePrep(self, date):
        # gets the preposition for a where question
        days = {"Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"}
        months = {"January", "February", "March", "April", "May", "June", "July", "August", "September", "November", "Decemeber"}
        if any(char.isdigit() for char in date):
            for word in date.split(" "):
                if word in days:
                    return "on"
                elif word in months:
                    return "on"
            return "in"
        else:
            for word in date.split(" "):
                if word in days:
                    return "on"
                elif word in months:
                    return "in"
            return "in"
            
    def getWhenAnswer(self, question, bestAnswer):
        #gets the answer for a when question
        words = question.split(" ")
        main,qverb = (" ".join(words[2:]), words[1])
        main.replace("?", "")
        nlp = en_core_web_sm.load()
        if main[-1] == "?":
            main = main[:-1]
        phrases = phrase_label_spacy.getNounVerbPhrasePairs(bestAnswer)
        if len(phrases) == 0:
            nouns = phrase_label_spacy.getNounPhrases(bestAnswer)
            preposition = self.getDatePrep(nouns[0])
            ans =  f'{main} {qverb} {preposition} {nouns[0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        if len(phrases) == 1:
            preposition = self.getDatePrep(phrases[0][0])
            ans =  f'{main} {qverb} {preposition} {phrases[0][0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        possible = []
        for phrase in phrases:
            flag = True
            noun, verb = phrase
            for w in noun.split(" "):
                #replace with stop word check instead
                if w in question and not nlp.vocab[w].is_stop:
                    flag = False
            if flag:
                possible.append(phrase)
        if len(possible) == 1:
            preposition = self.getDatePrep(possible[0][0])
            ans =  f'{main} {qverb} {preposition} {possible[0][0]}.'
            return self.formatWhereAnswer(words, ans, nlp)
        elif len(possible) == 0:
            possible = phrases
        np = self.bestNounPhrase(phrases, question)
        preposition = self.getDatePrep(np)
        ans =  f'{main} {qverb} {preposition} {np}.'
        return self.formatWhereAnswer(words, ans, nlp)

    def getAnswerBeginning(self, question, bestAnswer):
        # determines type of question
        try:
            words = question.split(" ")
            if words[0].lower() == "where":
                return self.getWhereAnswer(question, bestAnswer)
            elif words[0].lower() == "why":
                return self.getWhyAnswer(question, bestAnswer)
            elif words[0].lower() == "how":
                return bestAnswer
            elif words[0].lower() == "who":
                return self.getWhoAnswer(question, bestAnswer)            
            elif words[0].lower() == "what":
                return self.getWhatAnswer(question, bestAnswer)
            elif words[0].lower() == "does":
                return self.yesNoAnswer(question, bestAnswer)
            elif words[0].lower() == "is":
                return self.yesNoAnswer(question, bestAnswer)
            elif words[0].lower() == "which":
                return self.getWhatAnswer(question, bestAnswer)
            elif words[0].lower() == "when":
                return self.getWhenAnswer(question, bestAnswer)
            else:
                return bestAnswer
        except:
            return bestAnswer

    def getBestAnswer(self, text, question):
        # Gets the best answer for a question
        possible, best, length =  self.extract_sentences_keyword(text, question)
        answer =  self.getAnswerBeginning(question, best).strip().capitalize()
        if answer[-1] == "?":
            return answer[:-1] + "."
        return answer


def readFile(path):
    with open(path, "rt", encoding = 'latin-1') as f:
        return  f.read()

def getQuestions(path):
    contents = readFile(path)
    results = []
    for question in contents.splitlines():
        results.append(question)
    return results

def getAnswers(text, questions):
    text = cqg.readFile(text)
    questions = getQuestions(questions)
    parse = Parser()
    result = ""
    for question in questions:
        ans =  parse.getBestAnswer(text, question).capitalize()
        #print(ans)
        result += ans
        result += '\n'
    sys.stdout.write(result)
                

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('text', help='Path to corpus text')
    parser.add_argument('questions', help='Path to questions file')
    args = parser.parse_args()
    text = args.text
    questions = args.questions
    getAnswers(text, questions)

